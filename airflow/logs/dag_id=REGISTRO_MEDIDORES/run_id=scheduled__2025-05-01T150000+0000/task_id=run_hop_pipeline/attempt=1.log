[2025-06-27T02:22:29.687+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-27T02:22:29.781+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T02:22:29.813+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T02:22:29.814+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-06-27T02:22:29.881+0000] {taskinstance.py:2330} INFO - Executing <Task(DockerOperator): run_hop_pipeline> on 2025-05-01 15:00:00+00:00
[2025-06-27T02:22:29.905+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=67) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-27T02:22:29.912+0000] {standard_task_runner.py:63} INFO - Started process 70 to run task
[2025-06-27T02:22:29.921+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'REGISTRO_MEDIDORES', 'run_hop_pipeline', 'scheduled__2025-05-01T15:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/apache-hop-dag-pipeline-final-registro-medidores.py', '--cfg-path', '/tmp/tmptukrv9dv']
[2025-06-27T02:22:29.927+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask run_hop_pipeline
[2025-06-27T02:22:30.446+0000] {task_command.py:426} INFO - Running <TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [running]> on host 0b41c6d28592
[2025-06-27T02:22:30.834+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='REGISTRO_MEDIDORES' AIRFLOW_CTX_TASK_ID='run_hop_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-05-01T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-01T15:00:00+00:00'
[2025-06-27T02:22:30.837+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-27T02:22:30.967+0000] {docker.py:493} INFO - Pulling docker image apache/hop:latest
[2025-06-27T02:22:33.728+0000] {docker.py:507} INFO - latest: Pulling from apache/hop
[2025-06-27T02:22:37.974+0000] {docker.py:507} INFO - 4f4fb700ef54: Pulling fs layer
[2025-06-27T02:22:37.975+0000] {docker.py:507} INFO - 9b6bc2cf1037: Pulling fs layer
[2025-06-27T02:22:37.976+0000] {docker.py:507} INFO - bf26d906d0f5: Pulling fs layer
[2025-06-27T02:22:37.978+0000] {docker.py:507} INFO - eb2b48b7cabe: Pulling fs layer
[2025-06-27T02:22:37.979+0000] {docker.py:507} INFO - f488a4dddc73: Pulling fs layer
[2025-06-27T02:22:37.980+0000] {docker.py:507} INFO - f18232174bc9: Pulling fs layer
[2025-06-27T02:22:37.981+0000] {docker.py:507} INFO - d4d2578e96cd: Pulling fs layer
[2025-06-27T02:22:37.981+0000] {docker.py:507} INFO - 19f1029c3f10: Pulling fs layer
[2025-06-27T02:22:37.994+0000] {docker.py:507} INFO - 4f4fb700ef54: Already exists
[2025-06-27T02:22:37.999+0000] {docker.py:507} INFO - 4f4fb700ef54: Pull complete
[2025-06-27T02:22:38.292+0000] {docker.py:507} INFO - 9b6bc2cf1037: Downloading
[2025-06-27T02:22:38.697+0000] {docker.py:507} INFO - eb2b48b7cabe: Downloading
[2025-06-27T02:22:38.698+0000] {docker.py:507} INFO - d4d2578e96cd: Downloading
[2025-06-27T02:22:38.700+0000] {docker.py:507} INFO - f488a4dddc73: Downloading
[2025-06-27T02:22:39.102+0000] {docker.py:507} INFO - bf26d906d0f5: Downloading
[2025-06-27T02:22:39.334+0000] {docker.py:507} INFO - 19f1029c3f10: Downloading
[2025-06-27T02:22:39.335+0000] {docker.py:507} INFO - f18232174bc9: Downloading
[2025-06-27T02:22:47.912+0000] {docker.py:507} INFO - 9b6bc2cf1037: Download complete
[2025-06-27T02:22:48.147+0000] {docker.py:507} INFO - eb2b48b7cabe: Download complete
[2025-06-27T02:22:48.234+0000] {docker.py:507} INFO - d4d2578e96cd: Download complete
[2025-06-27T02:22:49.020+0000] {docker.py:507} INFO - bf26d906d0f5: Download complete
[2025-06-27T02:22:49.042+0000] {docker.py:507} INFO - f18232174bc9: Download complete
[2025-06-27T02:22:49.096+0000] {docker.py:507} INFO - f18232174bc9: Extracting
[2025-06-27T02:22:52.530+0000] {docker.py:507} INFO - 19f1029c3f10: Download complete
[2025-06-27T02:22:54.008+0000] {docker.py:507} INFO - f18232174bc9: Pull complete
[2025-06-27T02:23:00.902+0000] {docker.py:507} INFO - d4d2578e96cd: Extracting
[2025-06-27T02:23:06.512+0000] {docker.py:507} INFO - d4d2578e96cd: Pull complete
[2025-06-27T02:23:09.792+0000] {docker.py:507} INFO - 19f1029c3f10: Extracting
[2025-06-27T02:23:24.595+0000] {docker.py:507} INFO - 19f1029c3f10: Pull complete
[2025-06-27T02:23:30.287+0000] {docker.py:507} INFO - bf26d906d0f5: Extracting
[2025-06-27T02:23:31.091+0000] {docker.py:507} INFO - bf26d906d0f5: Pull complete
[2025-06-27T02:23:40.681+0000] {docker.py:507} INFO - f488a4dddc73: Download complete
[2025-06-27T02:23:40.692+0000] {docker.py:507} INFO - f488a4dddc73: Extracting
[2025-06-27T02:24:20.386+0000] {docker.py:507} INFO - f488a4dddc73: Pull complete
[2025-06-27T02:24:20.478+0000] {docker.py:507} INFO - 9b6bc2cf1037: Pull complete
[2025-06-27T02:24:20.678+0000] {docker.py:507} INFO - eb2b48b7cabe: Pull complete
[2025-06-27T02:24:21.145+0000] {docker.py:502} INFO - Digest: sha256:950a95da3332a2782706665b58adeed820689d87e0ca5b54df59bc995b2d955e
[2025-06-27T02:24:21.154+0000] {docker.py:502} INFO - Status: Downloaded newer image for apache/hop:latest
[2025-06-27T02:24:21.198+0000] {docker.py:366} INFO - Starting docker container from image apache/hop:latest
[2025-06-27T02:24:21.325+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-06-27T02:24:21.342+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 265, in _raise_for_status
    response.raise_for_status()
  File "/home/airflow/.local/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http+docker://localhost/v1.50/containers/create

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 509, in execute
    return self._run_image()
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 371, in _run_image
    return self._run_image_with_mounts([*self.mounts, tmp_mount], add_tmp_variable=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 398, in _run_image_with_mounts
    self.container = self.cli.create_container(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 439, in create_container
    return self.create_container_from_config(config, name, platform)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 456, in create_container_from_config
    return self._result(res, True)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 271, in _result
    self._raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 267, in _raise_for_status
    raise create_api_error_from_http_exception(e) from e
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/errors.py", line 39, in create_api_error_from_http_exception
    raise cls(e, response=response, explanation=explanation) from e
docker.errors.APIError: 400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /mnt/data/ProyectoSmart/ProyectoSmartMed")
[2025-06-27T02:24:21.465+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=REGISTRO_MEDIDORES, task_id=run_hop_pipeline, run_id=scheduled__2025-05-01T15:00:00+00:00, execution_date=20250501T150000, start_date=20250627T022229, end_date=20250627T022421
[2025-06-27T02:24:21.582+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 6 for task run_hop_pipeline (400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /mnt/data/ProyectoSmart/ProyectoSmartMed"); 70)
[2025-06-27T02:24:21.669+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-06-27T02:24:21.835+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-06-27T02:24:21.840+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-06-27T03:49:08.470+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-27T03:49:08.621+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T03:49:08.643+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T03:49:08.645+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-06-27T03:49:08.707+0000] {taskinstance.py:2330} INFO - Executing <Task(DockerOperator): run_hop_pipeline> on 2025-05-01 15:00:00+00:00
[2025-06-27T03:49:08.725+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=65) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-27T03:49:08.730+0000] {standard_task_runner.py:63} INFO - Started process 70 to run task
[2025-06-27T03:49:08.731+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'REGISTRO_MEDIDORES', 'run_hop_pipeline', 'scheduled__2025-05-01T15:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/apache-hop-dag-pipeline-final-registro-medidores.py', '--cfg-path', '/tmp/tmpfk7vdj3i']
[2025-06-27T03:49:08.733+0000] {standard_task_runner.py:91} INFO - Job 3: Subtask run_hop_pipeline
[2025-06-27T03:49:10.631+0000] {task_command.py:426} INFO - Running <TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [running]> on host 24f72b4a1d8f
[2025-06-27T03:49:11.872+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='REGISTRO_MEDIDORES' AIRFLOW_CTX_TASK_ID='run_hop_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-05-01T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-01T15:00:00+00:00'
[2025-06-27T03:49:12.015+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-27T03:49:12.411+0000] {docker.py:366} INFO - Starting docker container from image apache/hop:latest
[2025-06-27T03:49:12.432+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-06-27T03:49:12.433+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 265, in _raise_for_status
    response.raise_for_status()
  File "/home/airflow/.local/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http+docker://localhost/v1.50/containers/create

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 509, in execute
    return self._run_image()
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 371, in _run_image
    return self._run_image_with_mounts([*self.mounts, tmp_mount], add_tmp_variable=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 398, in _run_image_with_mounts
    self.container = self.cli.create_container(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 439, in create_container
    return self.create_container_from_config(config, name, platform)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 456, in create_container_from_config
    return self._result(res, True)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 271, in _result
    self._raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 267, in _raise_for_status
    raise create_api_error_from_http_exception(e) from e
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/errors.py", line 39, in create_api_error_from_http_exception
    raise cls(e, response=response, explanation=explanation) from e
docker.errors.APIError: 400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /mnt/data/ProyectoSmart/ProyectoSmartMed")
[2025-06-27T03:49:12.457+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=REGISTRO_MEDIDORES, task_id=run_hop_pipeline, run_id=scheduled__2025-05-01T15:00:00+00:00, execution_date=20250501T150000, start_date=20250627T034908, end_date=20250627T034912
[2025-06-27T03:49:12.494+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 3 for task run_hop_pipeline (400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /mnt/data/ProyectoSmart/ProyectoSmartMed"); 70)
[2025-06-27T03:49:12.554+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-06-27T03:49:12.617+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-06-27T03:49:12.624+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-06-27T04:12:46.550+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-06-27T04:12:46.612+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T04:12:46.635+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T04:12:46.639+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 2
[2025-06-27T04:12:46.678+0000] {taskinstance.py:2888} INFO - Executing <Task(DockerOperator): run_hop_pipeline> on 2025-05-01 15:00:00+00:00
[2025-06-27T04:12:46.699+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=64) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-27T04:12:46.702+0000] {standard_task_runner.py:72} INFO - Started process 69 to run task
[2025-06-27T04:12:46.707+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'REGISTRO_MEDIDORES', 'run_hop_pipeline', 'scheduled__2025-05-01T15:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/apache-hop-dag-pipeline-final-registro-medidores.py', '--cfg-path', '/tmp/tmp98y_t2m0']
[2025-06-27T04:12:46.716+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask run_hop_pipeline
[2025-06-27T04:12:47.619+0000] {task_command.py:467} INFO - Running <TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [running]> on host 9f6303ed7827
[2025-06-27T04:12:48.175+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='REGISTRO_MEDIDORES' AIRFLOW_CTX_TASK_ID='run_hop_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-05-01T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-01T15:00:00+00:00'
[2025-06-27T04:12:48.182+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-06-27T04:12:48.332+0000] {docker.py:496} INFO - ::group::Pulling docker image apache/hop:latest
[2025-06-27T04:12:52.101+0000] {docker.py:510} INFO - latest: Pulling from apache/hop
[2025-06-27T04:12:58.112+0000] {docker.py:510} INFO - 4f4fb700ef54: Pulling fs layer
[2025-06-27T04:12:58.115+0000] {docker.py:510} INFO - f18232174bc9: Pulling fs layer
[2025-06-27T04:12:58.135+0000] {docker.py:510} INFO - 19f1029c3f10: Pulling fs layer
[2025-06-27T04:12:58.136+0000] {docker.py:510} INFO - 9b6bc2cf1037: Pulling fs layer
[2025-06-27T04:12:58.137+0000] {docker.py:510} INFO - bf26d906d0f5: Pulling fs layer
[2025-06-27T04:12:58.139+0000] {docker.py:510} INFO - eb2b48b7cabe: Pulling fs layer
[2025-06-27T04:12:58.141+0000] {docker.py:510} INFO - d4d2578e96cd: Pulling fs layer
[2025-06-27T04:12:58.143+0000] {docker.py:510} INFO - f488a4dddc73: Pulling fs layer
[2025-06-27T04:12:58.172+0000] {docker.py:510} INFO - 4f4fb700ef54: Already exists
[2025-06-27T04:12:58.184+0000] {docker.py:510} INFO - 4f4fb700ef54: Pull complete
[2025-06-27T04:12:58.786+0000] {docker.py:510} INFO - f18232174bc9: Downloading
[2025-06-27T04:12:58.876+0000] {docker.py:510} INFO - eb2b48b7cabe: Downloading
[2025-06-27T04:12:59.086+0000] {docker.py:510} INFO - d4d2578e96cd: Downloading
[2025-06-27T04:12:59.093+0000] {docker.py:510} INFO - 9b6bc2cf1037: Downloading
[2025-06-27T04:12:59.178+0000] {docker.py:510} INFO - bf26d906d0f5: Downloading
[2025-06-27T04:12:59.443+0000] {docker.py:510} INFO - 19f1029c3f10: Downloading
[2025-06-27T04:12:59.478+0000] {docker.py:510} INFO - f488a4dddc73: Downloading
[2025-06-27T04:13:15.937+0000] {job.py:229} INFO - Heartbeat recovered after 13.92 seconds
[2025-06-27T04:13:20.292+0000] {docker.py:510} INFO - eb2b48b7cabe: Download complete
[2025-06-27T04:13:20.305+0000] {docker.py:510} INFO - f18232174bc9: Download complete
[2025-06-27T04:13:20.307+0000] {docker.py:510} INFO - f18232174bc9: Extracting
[2025-06-27T04:13:21.181+0000] {docker.py:510} INFO - 9b6bc2cf1037: Download complete
[2025-06-27T04:13:21.376+0000] {job.py:229} INFO - Heartbeat recovered after 12.31 seconds
[2025-06-27T04:13:21.485+0000] {docker.py:510} INFO - d4d2578e96cd: Download complete
[2025-06-27T04:13:21.680+0000] {docker.py:510} INFO - bf26d906d0f5: Download complete
[2025-06-27T04:13:25.397+0000] {docker.py:510} INFO - 19f1029c3f10: Download complete
[2025-06-27T04:13:29.013+0000] {docker.py:510} INFO - f18232174bc9: Pull complete
[2025-06-27T04:13:34.592+0000] {docker.py:510} INFO - d4d2578e96cd: Extracting
[2025-06-27T04:13:36.762+0000] {docker.py:510} INFO - d4d2578e96cd: Pull complete
[2025-06-27T04:13:41.463+0000] {docker.py:510} INFO - 19f1029c3f10: Extracting
[2025-06-27T04:14:13.245+0000] {docker.py:510} INFO - 19f1029c3f10: Pull complete
[2025-06-27T04:14:25.511+0000] {job.py:229} INFO - Heartbeat recovered after 11.19 seconds
[2025-06-27T04:14:30.746+0000] {job.py:229} INFO - Heartbeat recovered after 11.10 seconds
[2025-06-27T04:14:31.852+0000] {docker.py:510} INFO - bf26d906d0f5: Extracting
[2025-06-27T04:14:33.369+0000] {docker.py:510} INFO - bf26d906d0f5: Pull complete
[2025-06-27T04:14:41.811+0000] {docker.py:510} INFO - f488a4dddc73: Download complete
[2025-06-27T04:14:41.823+0000] {docker.py:510} INFO - f488a4dddc73: Extracting
[2025-06-27T04:16:07.278+0000] {docker.py:510} INFO - f488a4dddc73: Pull complete
[2025-06-27T04:16:07.388+0000] {docker.py:510} INFO - 9b6bc2cf1037: Pull complete
[2025-06-27T04:16:07.473+0000] {docker.py:510} INFO - eb2b48b7cabe: Pull complete
[2025-06-27T04:16:07.745+0000] {docker.py:505} INFO - Digest: sha256:950a95da3332a2782706665b58adeed820689d87e0ca5b54df59bc995b2d955e
[2025-06-27T04:16:07.748+0000] {docker.py:505} INFO - Status: Downloaded newer image for apache/hop:latest
[2025-06-27T04:16:07.753+0000] {docker.py:512} INFO - ::endgroup::
[2025-06-27T04:16:07.754+0000] {docker.py:367} INFO - Starting docker container from image apache/hop:latest
[2025-06-27T04:16:07.908+0000] {taskinstance.py:3310} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 275, in _raise_for_status
    response.raise_for_status()
  File "/home/airflow/.local/lib/python3.12/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http+docker://localhost/v1.50/containers/create

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 513, in execute
    return self._run_image()
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 372, in _run_image
    return self._run_image_with_mounts([*self.mounts, tmp_mount], add_tmp_variable=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 399, in _run_image_with_mounts
    self.container = self.cli.create_container(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 440, in create_container
    return self.create_container_from_config(config, name, platform)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 457, in create_container_from_config
    return self._result(res, True)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 281, in _result
    self._raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 277, in _raise_for_status
    raise create_api_error_from_http_exception(e) from e
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/errors.py", line 39, in create_api_error_from_http_exception
    raise cls(e, response=response, explanation=explanation) from e
docker.errors.APIError: 400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /mnt/data/ProyectoSmart/ProyectoSmartMed")
[2025-06-27T04:16:07.965+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=REGISTRO_MEDIDORES, task_id=run_hop_pipeline, run_id=scheduled__2025-05-01T15:00:00+00:00, execution_date=20250501T150000, start_date=20250627T041246, end_date=20250627T041607
[2025-06-27T04:16:08.043+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-06-27T04:16:08.044+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 3 for task run_hop_pipeline (400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /mnt/data/ProyectoSmart/ProyectoSmartMed"); 69)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 275, in _raise_for_status
    response.raise_for_status()
  File "/home/airflow/.local/lib/python3.12/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http+docker://localhost/v1.50/containers/create

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 115, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3004, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3158, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3182, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 513, in execute
    return self._run_image()
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 372, in _run_image
    return self._run_image_with_mounts([*self.mounts, tmp_mount], add_tmp_variable=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 399, in _run_image_with_mounts
    self.container = self.cli.create_container(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 440, in create_container
    return self.create_container_from_config(config, name, platform)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 457, in create_container_from_config
    return self._result(res, True)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 281, in _result
    self._raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 277, in _raise_for_status
    raise create_api_error_from_http_exception(e) from e
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/errors.py", line 39, in create_api_error_from_http_exception
    raise cls(e, response=response, explanation=explanation) from e
docker.errors.APIError: 400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /mnt/data/ProyectoSmart/ProyectoSmartMed")
[2025-06-27T04:16:08.097+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-06-27T04:16:08.155+0000] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-06-27T04:16:08.170+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-06-27T04:48:28.154+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-06-27T04:48:28.248+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T04:48:28.269+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T04:48:28.270+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 2
[2025-06-27T04:48:28.327+0000] {taskinstance.py:2888} INFO - Executing <Task(DockerOperator): run_hop_pipeline> on 2025-05-01 15:00:00+00:00
[2025-06-27T04:48:28.356+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=63) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-27T04:48:28.361+0000] {standard_task_runner.py:72} INFO - Started process 68 to run task
[2025-06-27T04:48:28.363+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'REGISTRO_MEDIDORES', 'run_hop_pipeline', 'scheduled__2025-05-01T15:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/apache-hop-dag-pipeline-final-registro-medidores.py', '--cfg-path', '/tmp/tmpxurgris5']
[2025-06-27T04:48:28.367+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask run_hop_pipeline
[2025-06-27T04:48:28.680+0000] {task_command.py:467} INFO - Running <TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [running]> on host 11460eb2799d
[2025-06-27T04:48:29.005+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='REGISTRO_MEDIDORES' AIRFLOW_CTX_TASK_ID='run_hop_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-05-01T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-01T15:00:00+00:00'
[2025-06-27T04:48:29.010+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-06-27T04:48:29.399+0000] {docker.py:367} INFO - Starting docker container from image apache/hop:latest
[2025-06-27T04:48:29.440+0000] {taskinstance.py:3310} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 275, in _raise_for_status
    response.raise_for_status()
  File "/home/airflow/.local/lib/python3.12/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http+docker://localhost/v1.50/containers/create

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 513, in execute
    return self._run_image()
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 372, in _run_image
    return self._run_image_with_mounts([*self.mounts, tmp_mount], add_tmp_variable=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 399, in _run_image_with_mounts
    self.container = self.cli.create_container(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 440, in create_container
    return self.create_container_from_config(config, name, platform)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 457, in create_container_from_config
    return self._result(res, True)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 281, in _result
    self._raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 277, in _raise_for_status
    raise create_api_error_from_http_exception(e) from e
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/errors.py", line 39, in create_api_error_from_http_exception
    raise cls(e, response=response, explanation=explanation) from e
docker.errors.APIError: 400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /mnt/data/ProyectoSmart/ProyectoSmartMed")
[2025-06-27T04:48:29.528+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=REGISTRO_MEDIDORES, task_id=run_hop_pipeline, run_id=scheduled__2025-05-01T15:00:00+00:00, execution_date=20250501T150000, start_date=20250627T044828, end_date=20250627T044829
[2025-06-27T04:48:29.584+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-06-27T04:48:29.590+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 3 for task run_hop_pipeline (400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /mnt/data/ProyectoSmart/ProyectoSmartMed"); 68)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 275, in _raise_for_status
    response.raise_for_status()
  File "/home/airflow/.local/lib/python3.12/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http+docker://localhost/v1.50/containers/create

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 115, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3004, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3158, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3182, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 513, in execute
    return self._run_image()
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 372, in _run_image
    return self._run_image_with_mounts([*self.mounts, tmp_mount], add_tmp_variable=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 399, in _run_image_with_mounts
    self.container = self.cli.create_container(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 440, in create_container
    return self.create_container_from_config(config, name, platform)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 457, in create_container_from_config
    return self._result(res, True)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 281, in _result
    self._raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 277, in _raise_for_status
    raise create_api_error_from_http_exception(e) from e
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/errors.py", line 39, in create_api_error_from_http_exception
    raise cls(e, response=response, explanation=explanation) from e
docker.errors.APIError: 400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /mnt/data/ProyectoSmart/ProyectoSmartMed")
[2025-06-27T04:48:29.664+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-06-27T04:48:29.780+0000] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-06-27T04:48:29.785+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-06-27T04:59:17.282+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-27T04:59:17.343+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T04:59:17.366+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T04:59:17.367+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-06-27T04:59:17.402+0000] {taskinstance.py:2330} INFO - Executing <Task(DockerOperator): run_hop_pipeline> on 2025-05-01 15:00:00+00:00
[2025-06-27T04:59:17.413+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=65) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-27T04:59:17.419+0000] {standard_task_runner.py:63} INFO - Started process 70 to run task
[2025-06-27T04:59:17.422+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'REGISTRO_MEDIDORES', 'run_hop_pipeline', 'scheduled__2025-05-01T15:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/apache-hop-dag-pipeline-final-registro-medidores.py', '--cfg-path', '/tmp/tmphqzo2m27']
[2025-06-27T04:59:17.425+0000] {standard_task_runner.py:91} INFO - Job 4: Subtask run_hop_pipeline
[2025-06-27T04:59:17.626+0000] {task_command.py:426} INFO - Running <TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [running]> on host 4c575de26931
[2025-06-27T04:59:17.853+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='REGISTRO_MEDIDORES' AIRFLOW_CTX_TASK_ID='run_hop_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-05-01T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-01T15:00:00+00:00'
[2025-06-27T04:59:17.855+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-27T04:59:18.156+0000] {docker.py:366} INFO - Starting docker container from image apache/hop:latest
[2025-06-27T04:59:18.197+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-06-27T04:59:18.202+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 265, in _raise_for_status
    response.raise_for_status()
  File "/home/airflow/.local/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http+docker://localhost/v1.50/containers/create

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 509, in execute
    return self._run_image()
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 371, in _run_image
    return self._run_image_with_mounts([*self.mounts, tmp_mount], add_tmp_variable=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 398, in _run_image_with_mounts
    self.container = self.cli.create_container(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 439, in create_container
    return self.create_container_from_config(config, name, platform)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 456, in create_container_from_config
    return self._result(res, True)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 271, in _result
    self._raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 267, in _raise_for_status
    raise create_api_error_from_http_exception(e) from e
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/errors.py", line 39, in create_api_error_from_http_exception
    raise cls(e, response=response, explanation=explanation) from e
docker.errors.APIError: 400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /mnt/data/ProyectoSmart/ProyectoSmartMed")
[2025-06-27T04:59:18.245+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=REGISTRO_MEDIDORES, task_id=run_hop_pipeline, run_id=scheduled__2025-05-01T15:00:00+00:00, execution_date=20250501T150000, start_date=20250627T045917, end_date=20250627T045918
[2025-06-27T04:59:18.284+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 4 for task run_hop_pipeline (400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /mnt/data/ProyectoSmart/ProyectoSmartMed"); 70)
[2025-06-27T04:59:18.329+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-06-27T04:59:18.368+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-06-27T05:41:02.246+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-27T05:41:02.346+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T05:41:02.365+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T05:41:02.369+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-06-27T05:41:02.433+0000] {taskinstance.py:2330} INFO - Executing <Task(DockerOperator): run_hop_pipeline> on 2025-05-01 15:00:00+00:00
[2025-06-27T05:41:02.463+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=66) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-27T05:41:02.472+0000] {standard_task_runner.py:63} INFO - Started process 73 to run task
[2025-06-27T05:41:02.475+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'REGISTRO_MEDIDORES', 'run_hop_pipeline', 'scheduled__2025-05-01T15:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/apache-hop-dag-pipeline-final-registro-medidores.py', '--cfg-path', '/tmp/tmpe9d0n617']
[2025-06-27T05:41:02.477+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask run_hop_pipeline
[2025-06-27T05:41:02.801+0000] {task_command.py:426} INFO - Running <TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [running]> on host 760ca3d6cb03
[2025-06-27T05:41:03.042+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='REGISTRO_MEDIDORES' AIRFLOW_CTX_TASK_ID='run_hop_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-05-01T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-01T15:00:00+00:00'
[2025-06-27T05:41:03.044+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-27T05:41:03.304+0000] {docker.py:366} INFO - Starting docker container from image apache/hop:latest
[2025-06-27T05:41:03.356+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-06-27T05:41:03.357+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 265, in _raise_for_status
    response.raise_for_status()
  File "/home/airflow/.local/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http+docker://localhost/v1.50/containers/create

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 509, in execute
    return self._run_image()
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 371, in _run_image
    return self._run_image_with_mounts([*self.mounts, tmp_mount], add_tmp_variable=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 398, in _run_image_with_mounts
    self.container = self.cli.create_container(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 439, in create_container
    return self.create_container_from_config(config, name, platform)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 456, in create_container_from_config
    return self._result(res, True)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 271, in _result
    self._raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 267, in _raise_for_status
    raise create_api_error_from_http_exception(e) from e
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/errors.py", line 39, in create_api_error_from_http_exception
    raise cls(e, response=response, explanation=explanation) from e
docker.errors.APIError: 400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /opt/airflow/ProyectoSmartMed")
[2025-06-27T05:41:03.391+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=REGISTRO_MEDIDORES, task_id=run_hop_pipeline, run_id=scheduled__2025-05-01T15:00:00+00:00, execution_date=20250501T150000, start_date=20250627T054102, end_date=20250627T054103
[2025-06-27T05:41:03.461+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 6 for task run_hop_pipeline (400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /opt/airflow/ProyectoSmartMed"); 73)
[2025-06-27T05:41:03.526+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-06-27T05:41:03.663+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-06-27T05:41:03.685+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-06-27T06:11:13.209+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-27T06:11:13.291+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T06:11:13.309+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T06:11:13.309+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-06-27T06:11:13.347+0000] {taskinstance.py:2330} INFO - Executing <Task(DockerOperator): run_hop_pipeline> on 2025-05-01 15:00:00+00:00
[2025-06-27T06:11:13.366+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=66) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-27T06:11:13.372+0000] {standard_task_runner.py:63} INFO - Started process 74 to run task
[2025-06-27T06:11:13.372+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'REGISTRO_MEDIDORES', 'run_hop_pipeline', 'scheduled__2025-05-01T15:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/apache-hop-dag-pipeline-final-registro-medidores.py', '--cfg-path', '/tmp/tmptrtt47zw']
[2025-06-27T06:11:13.375+0000] {standard_task_runner.py:91} INFO - Job 5: Subtask run_hop_pipeline
[2025-06-27T06:11:13.729+0000] {task_command.py:426} INFO - Running <TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [running]> on host 9bc187bed6c8
[2025-06-27T06:11:14.020+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='REGISTRO_MEDIDORES' AIRFLOW_CTX_TASK_ID='run_hop_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-05-01T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-01T15:00:00+00:00'
[2025-06-27T06:11:14.024+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-27T06:11:14.240+0000] {docker.py:366} INFO - Starting docker container from image apache/hop:latest
[2025-06-27T06:11:14.261+0000] {docker.py:374} WARNING - Using remote engine or docker-in-docker and mounting temporary volume from host is not supported. Falling back to `mount_tmp_dir=False` mode. You can set `mount_tmp_dir` parameter to False to disable mounting and remove the warning
[2025-06-27T06:11:16.415+0000] {docker.py:436} INFO - 2025/06/27 06:11:16 - The project folder for ProyectoSmartMed is set to: /files
[2025-06-27T06:11:16.423+0000] {docker.py:436} INFO - 2025/06/27 06:11:16 - Running the entrypoint script with PID 7
[2025-06-27T06:11:16.449+0000] {docker.py:436} INFO - 2025/06/27 06:11:16 - The specified project folder exists
[2025-06-27T06:11:16.452+0000] {docker.py:436} INFO - 2025/06/27 06:11:16 - Registering project ProyectoSmartMed in the Hop container configuration
[2025-06-27T06:11:16.459+0000] {docker.py:436} INFO - 2025/06/27 06:11:16 - /opt/hop/hop-conf.sh --project=ProyectoSmartMed --project-create --project-home='/files' --project-config-file='project-config.json'
[2025-06-27T06:46:18.217+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-27T06:46:18.279+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T06:46:18.297+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T06:46:18.298+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-06-27T06:46:18.339+0000] {taskinstance.py:2330} INFO - Executing <Task(DockerOperator): run_hop_pipeline> on 2025-05-01 15:00:00+00:00
[2025-06-27T06:46:18.356+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=68) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-27T06:46:18.360+0000] {standard_task_runner.py:63} INFO - Started process 72 to run task
[2025-06-27T06:46:18.373+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'REGISTRO_MEDIDORES', 'run_hop_pipeline', 'scheduled__2025-05-01T15:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/apache-hop-dag-pipeline-final-registro-medidores.py', '--cfg-path', '/tmp/tmp3_n3hs9q']
[2025-06-27T06:46:18.376+0000] {standard_task_runner.py:91} INFO - Job 7: Subtask run_hop_pipeline
[2025-06-27T06:46:18.550+0000] {task_command.py:426} INFO - Running <TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [running]> on host eefc0d82eb46
[2025-06-27T06:46:18.817+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='REGISTRO_MEDIDORES' AIRFLOW_CTX_TASK_ID='run_hop_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-05-01T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-01T15:00:00+00:00'
[2025-06-27T06:46:18.820+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-27T06:46:19.041+0000] {docker.py:366} INFO - Starting docker container from image apache/hop:latest
[2025-06-27T06:46:19.069+0000] {docker.py:374} WARNING - Using remote engine or docker-in-docker and mounting temporary volume from host is not supported. Falling back to `mount_tmp_dir=False` mode. You can set `mount_tmp_dir` parameter to False to disable mounting and remove the warning
[2025-06-27T06:46:20.224+0000] {docker.py:436} INFO - 2025/06/27 06:46:20 - Running the entrypoint script with PID 7
[2025-06-27T06:46:20.227+0000] {docker.py:436} INFO - 2025/06/27 06:46:20 - The project folder for ProyectoSmartMed is set to: /files
[2025-06-27T06:46:20.233+0000] {docker.py:436} INFO - 2025/06/27 06:46:20 - The specified project folder exists
[2025-06-27T06:46:20.243+0000] {docker.py:436} INFO - 2025/06/27 06:46:20 - Registering project ProyectoSmartMed in the Hop container configuration
[2025-06-27T06:46:20.246+0000] {docker.py:436} INFO - 2025/06/27 06:46:20 - /opt/hop/hop-conf.sh --project=ProyectoSmartMed --project-create --project-home='/files' --project-config-file='project-config.json'
[2025-06-27T06:47:23.508+0000] {docker.py:436} INFO - Creating project 'ProyectoSmartMed'
[2025-06-27T06:47:24.115+0000] {docker.py:436} INFO - Project 'ProyectoSmartMed' was created for home folder : /files
[2025-06-27T06:47:24.308+0000] {docker.py:436} INFO - Configuration file for project 'ProyectoSmartMed' was saved to : file:/files/project-config.json
[2025-06-27T06:47:24.544+0000] {docker.py:436} INFO - 2025/06/27 06:47:24 - Not creating an environment in the container
[2025-06-27T06:47:24.549+0000] {docker.py:436} INFO - 2025/06/27 06:47:24 - Running a single hop workflow / pipeline (${PROJECT_HOME}/Pipelines/FINAL_REGISTRO_MEDIDORES.hpl)
[2025-06-27T06:47:50.753+0000] {docker.py:436} INFO - 2025/06/27 06:47:50 - HopRun - Enabling project 'ProyectoSmartMed'
[2025-06-27T06:47:51.195+0000] {docker.py:436} INFO - 2025/06/27 06:47:51 - HopRun - Starting pipeline: /files/Pipelines/FINAL_REGISTRO_MEDIDORES.hpl
[2025-06-27T06:47:51.209+0000] {docker.py:436} INFO - 2025/06/27 06:47:51 - FINAL_REGISTRO_MEDIDORES - Executing this pipeline using the Local Pipeline Engine with run configuration 'local'
[2025-06-27T06:47:51.248+0000] {docker.py:436} INFO - 2025/06/27 06:47:51 - FINAL_REGISTRO_MEDIDORES - Execution started for pipeline [FINAL_REGISTRO_MEDIDORES]
[2025-06-27T06:47:54.913+0000] {docker.py:436} INFO - 2025/06/27 06:47:54 - Table output.0 - Connected to database [POSTGRES_SMART] (commit=1000)
[2025-06-27T06:47:57.878+0000] {docker.py:436} INFO - 2025/06/27 06:47:57 - final_medidores.0 - Finished reading query, closing connection.
[2025-06-27T06:47:57.993+0000] {docker.py:436} INFO - 2025/06/27 06:47:57 - final_medidores.0 - Finished processing (I=144, O=0, R=0, W=144, U=0, E=0)
[2025-06-27T06:47:58.253+0000] {docker.py:436} INFO - 2025/06/27 06:47:58 - Table output.0 - Finished processing (I=0, O=144, R=144, W=144, U=0, E=0)
[2025-06-27T06:47:58.267+0000] {docker.py:436} INFO - 2025/06/27 06:47:58 - FINAL_REGISTRO_MEDIDORES - Pipeline duration : 7.05 seconds [  7.049" ]
[2025-06-27T06:47:58.385+0000] {docker.py:436} INFO - 2025/06/27 06:47:58 - FINAL_REGISTRO_MEDIDORES - Execution finished on a local pipeline engine with run configuration 'local'
HopRun exit.
[2025-06-27T06:47:59.832+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-06-27T06:47:59.961+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=REGISTRO_MEDIDORES, task_id=run_hop_pipeline, run_id=scheduled__2025-05-01T15:00:00+00:00, execution_date=20250501T150000, start_date=20250627T064618, end_date=20250627T064759
[2025-06-27T06:48:00.086+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-06-27T06:48:00.205+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-06-27T06:48:00.224+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-06-27T07:20:45.943+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-27T07:20:46.038+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T07:20:46.070+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T07:20:46.074+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-06-27T07:20:46.139+0000] {taskinstance.py:2330} INFO - Executing <Task(DockerOperator): run_hop_pipeline> on 2025-05-01 15:00:00+00:00
[2025-06-27T07:20:46.167+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=68) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-27T07:20:46.179+0000] {standard_task_runner.py:63} INFO - Started process 71 to run task
[2025-06-27T07:20:46.182+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'REGISTRO_MEDIDORES', 'run_hop_pipeline', 'scheduled__2025-05-01T15:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/apache-hop-dag-pipeline-final-registro-medidores.py', '--cfg-path', '/tmp/tmp82ba0l72']
[2025-06-27T07:20:46.186+0000] {standard_task_runner.py:91} INFO - Job 3: Subtask run_hop_pipeline
[2025-06-27T07:20:46.495+0000] {task_command.py:426} INFO - Running <TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [running]> on host 5e15c4a8eeb7
[2025-06-27T07:20:46.771+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='REGISTRO_MEDIDORES' AIRFLOW_CTX_TASK_ID='run_hop_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-05-01T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-01T15:00:00+00:00'
[2025-06-27T07:20:46.780+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-27T07:20:47.002+0000] {docker.py:366} INFO - Starting docker container from image apache/hop:latest
[2025-06-27T07:20:47.065+0000] {docker.py:374} WARNING - Using remote engine or docker-in-docker and mounting temporary volume from host is not supported. Falling back to `mount_tmp_dir=False` mode. You can set `mount_tmp_dir` parameter to False to disable mounting and remove the warning
[2025-06-27T07:20:48.275+0000] {docker.py:436} INFO - 2025/06/27 07:20:48 - The project folder for ProyectoSmartMed is set to: /files
2025/06/27 07:20:48 - Running the entrypoint script with PID 6
[2025-06-27T07:20:48.287+0000] {docker.py:436} INFO - 2025/06/27 07:20:48 - The specified project folder exists
[2025-06-27T07:20:48.291+0000] {docker.py:436} INFO - 2025/06/27 07:20:48 - Registering project ProyectoSmartMed in the Hop container configuration
[2025-06-27T07:20:48.292+0000] {docker.py:436} INFO - 2025/06/27 07:20:48 - /opt/hop/hop-conf.sh --project=ProyectoSmartMed --project-create --project-home='/files' --project-config-file='project-config.json'
[2025-06-27T07:22:15.326+0000] {docker.py:436} INFO - Creating project 'ProyectoSmartMed'
[2025-06-27T07:22:16.608+0000] {docker.py:436} INFO - Project 'ProyectoSmartMed' was created for home folder : /files
[2025-06-27T07:22:16.885+0000] {docker.py:436} INFO - Configuration file for project 'ProyectoSmartMed' was saved to : file:/files/project-config.json
[2025-06-27T07:22:17.192+0000] {docker.py:436} INFO - 2025/06/27 07:22:17 - Not creating an environment in the container
[2025-06-27T07:22:17.196+0000] {docker.py:436} INFO - 2025/06/27 07:22:17 - Running a single hop workflow / pipeline (${PROJECT_HOME}/Pipelines/FINAL_REGISTRO_MEDIDORES.hpl)
[2025-06-27T07:22:54.591+0000] {docker.py:436} INFO - 2025/06/27 07:22:54 - HopRun - Enabling project 'ProyectoSmartMed'
[2025-06-27T07:22:55.498+0000] {docker.py:436} INFO - 2025/06/27 07:22:55 - HopRun - Starting pipeline: /files/Pipelines/FINAL_REGISTRO_MEDIDORES.hpl
[2025-06-27T07:22:55.518+0000] {docker.py:436} INFO - 2025/06/27 07:22:55 - FINAL_REGISTRO_MEDIDORES - Executing this pipeline using the Local Pipeline Engine with run configuration 'local'
[2025-06-27T07:22:55.590+0000] {docker.py:436} INFO - 2025/06/27 07:22:55 - FINAL_REGISTRO_MEDIDORES - Execution started for pipeline [FINAL_REGISTRO_MEDIDORES]
[2025-06-27T07:23:08.962+0000] {docker.py:436} INFO - 2025/06/27 07:23:08 - final_medidores.0 - ERROR: An error occurred, processing will be stopped: 
2025/06/27 07:23:08 - final_medidores.0 - Error occurred while trying to connect to the database
2025/06/27 07:23:08 - final_medidores.0 - 
2025/06/27 07:23:08 - final_medidores.0 - Error connecting to database: (using class org.postgresql.Driver)
2025/06/27 07:23:08 - final_medidores.0 - The connection attempt failed.
[2025-06-27T07:23:08.967+0000] {docker.py:436} INFO - 2025/06/27 07:23:08 - Table output.0 - ERROR: An error occurred initializing this transform: 
2025/06/27 07:23:08 - Table output.0 - Error occurred while trying to connect to the database
2025/06/27 07:23:08 - Table output.0 - 
2025/06/27 07:23:08 - Table output.0 - Error connecting to database: (using class org.postgresql.Driver)
2025/06/27 07:23:08 - Table output.0 - The connection attempt failed.
[2025-06-27T07:23:08.970+0000] {docker.py:436} INFO - 2025/06/27 07:23:08 - Table output.0 - ERROR: Error initializing transform [Table output]
[2025-06-27T07:23:08.972+0000] {docker.py:436} INFO - 2025/06/27 07:23:08 - final_medidores.0 - ERROR: Error initializing transform [final_medidores]
[2025-06-27T07:23:08.978+0000] {docker.py:436} INFO - 2025/06/27 07:23:08 - FINAL_REGISTRO_MEDIDORES - ERROR: Transform [final_medidores.0] failed to initialize!
[2025-06-27T07:23:08.987+0000] {docker.py:436} INFO - 2025/06/27 07:23:08 - FINAL_REGISTRO_MEDIDORES - ERROR: Transform [Table output.0] failed to initialize!
[2025-06-27T07:23:08.993+0000] {docker.py:436} INFO - 2025/06/27 07:23:08 - final_medidores.0 - Finished reading query, closing connection.
[2025-06-27T07:23:08.994+0000] {docker.py:436} INFO - 2025/06/27 07:23:08 - Table output.0 - ERROR: Unexpected error rolling back the database connection.
[2025-06-27T07:23:09.002+0000] {docker.py:436} INFO - 2025/06/27 07:23:08 - Table output.0 - ERROR: org.apache.hop.core.exception.HopDatabaseException: 
2025/06/27 07:23:08 - Table output.0 - Unable to get database metadata from this database connection
2025/06/27 07:23:08 - Table output.0 - 
2025/06/27 07:23:08 - Table output.0 - Error connecting to database [***]
2025/06/27 07:23:08 - Table output.0 - 
2025/06/27 07:23:08 - Table output.0 - 
2025/06/27 07:23:08 - Table output.0 - 	at org.apache.hop.core.database.Database.getDatabaseMetaData(Database.java:2897)
2025/06/27 07:23:08 - Table output.0 - 	at org.apache.hop.core.database.Database.rollback(Database.java:737)
2025/06/27 07:23:08 - Table output.0 - 	at org.apache.hop.core.database.Database.rollback(Database.java:729)
2025/06/27 07:23:08 - Table output.0 - 	at org.apache.hop.pipeline.transforms.tableoutput.TableOutput.emptyAndCommitBatchBuffers(TableOutput.java:648)
2025/06/27 07:23:08 - Table output.0 - 	at org.apache.hop.pipeline.transforms.tableoutput.TableOutput.dispose(TableOutput.java:568)
2025/06/27 07:23:08 - Table output.0 - 	at org.apache.hop.pipeline.Pipeline.prepareExecution(Pipeline.java:1056)
2025/06/27 07:23:08 - Table output.0 - 	at org.apache.hop.pipeline.engines.local.LocalPipelineEngine.prepareExecution(LocalPipelineEngine.java:232)
2025/06/27 07:23:08 - Table output.0 - 	at org.apache.hop.run.HopRun.runPipeline(HopRun.java:335)
2025/06/27 07:23:08 - Table output.0 - 	at org.apache.hop.run.HopRun.runPipeline(HopRun.java:292)
2025/06/27 07:23:08 - Table output.0 - 	at org.apache.hop.run.HopRun.run(HopRun.java:203)
2025/06/27 07:23:08 - Table output.0 - 	at org.apache.hop.run.HopRun.main(HopRun.java:931)
2025/06/27 07:23:08 - Table output.0 - Caused by: org.apache.hop.core.exception.HopDatabaseException: 
2025/06/27 07:23:08 - Table output.0 - Error connecting to database [***]
2025/06/27 07:23:08 - Table output.0 - 
2025/06/27 07:23:08 - Table output.0 - 	at org.apache.hop.core.database.Database.getDatabaseMetaData(Database.java:2890)
2025/06/27 07:23:08 - Table output.0 - 	... 10 more
[2025-06-27T07:23:09.023+0000] {docker.py:436} INFO - Error found during execution!
[2025-06-27T07:23:09.032+0000] {docker.py:436} INFO - picocli.CommandLine$ExecutionException: There was an error during execution of file '${PROJECT_HOME}/Pipelines/FINAL_REGISTRO_MEDIDORES.hpl'
	at org.apache.hop.run.HopRun.run(HopRun.java:212)
	at org.apache.hop.run.HopRun.main(HopRun.java:931)
Caused by: picocli.CommandLine$ExecutionException: There was an error during execution of pipeline '${PROJECT_HOME}/Pipelines/FINAL_REGISTRO_MEDIDORES.hpl'
	at org.apache.hop.run.HopRun.runPipeline(HopRun.java:294)
	at org.apache.hop.run.HopRun.run(HopRun.java:203)
	... 1 more
Caused by: picocli.CommandLine$ExecutionException: Error running pipeline locally
	at org.apache.hop.run.HopRun.runPipeline(HopRun.java:340)
	at org.apache.hop.run.HopRun.runPipeline(HopRun.java:292)
	... 2 more
Caused by: org.apache.hop.core.exception.HopException: 
We failed to initialize at least one transform.  Execution can not begin!


	at org.apache.hop.pipeline.Pipeline.prepareExecution(Pipeline.java:1088)
	at org.apache.hop.pipeline.engines.local.LocalPipelineEngine.prepareExecution(LocalPipelineEngine.java:232)
	at org.apache.hop.run.HopRun.runPipeline(HopRun.java:335)
	... 3 more
[2025-06-27T07:23:10.370+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-06-27T07:23:10.428+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 265, in _raise_for_status
    response.raise_for_status()
  File "/home/airflow/.local/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http+docker://localhost/v1.50/containers/create

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 371, in _run_image
    return self._run_image_with_mounts([*self.mounts, tmp_mount], add_tmp_variable=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 398, in _run_image_with_mounts
    self.container = self.cli.create_container(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 439, in create_container
    return self.create_container_from_config(config, name, platform)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py", line 456, in create_container_from_config
    return self._result(res, True)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 271, in _result
    self._raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py", line 267, in _raise_for_status
    raise create_api_error_from_http_exception(e) from e
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/docker/errors.py", line 39, in create_api_error_from_http_exception
    raise cls(e, response=response, explanation=explanation) from e
docker.errors.APIError: 400 Client Error for http+docker://localhost/v1.50/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /tmp/airflowtmpfywr6h2d")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 509, in execute
    return self._run_image()
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 380, in _run_image
    return self._run_image_with_mounts(self.mounts, add_tmp_variable=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 444, in _run_image_with_mounts
    raise DockerContainerFailedException(f"Docker container failed: {result!r}", logs=log_lines)
airflow.providers.docker.exceptions.DockerContainerFailedException: Docker container failed: {'StatusCode': 1}
[2025-06-27T07:23:10.491+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=REGISTRO_MEDIDORES, task_id=run_hop_pipeline, run_id=scheduled__2025-05-01T15:00:00+00:00, execution_date=20250501T150000, start_date=20250627T072046, end_date=20250627T072310
[2025-06-27T07:23:10.686+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 3 for task run_hop_pipeline (Docker container failed: {'StatusCode': 1}; 71)
[2025-06-27T07:23:10.784+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-06-27T07:23:11.005+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-06-27T07:23:11.009+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-06-27T07:37:09.178+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-27T07:37:09.224+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T07:37:09.241+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [queued]>
[2025-06-27T07:37:09.242+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-06-27T07:37:09.267+0000] {taskinstance.py:2330} INFO - Executing <Task(DockerOperator): run_hop_pipeline> on 2025-05-01 15:00:00+00:00
[2025-06-27T07:37:09.280+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=65) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-27T07:37:09.283+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'REGISTRO_MEDIDORES', 'run_hop_pipeline', 'scheduled__2025-05-01T15:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/apache-hop-dag-pipeline-final-registro-medidores.py', '--cfg-path', '/tmp/tmphcmcd34t']
[2025-06-27T07:37:09.285+0000] {standard_task_runner.py:63} INFO - Started process 71 to run task
[2025-06-27T07:37:09.288+0000] {standard_task_runner.py:91} INFO - Job 7: Subtask run_hop_pipeline
[2025-06-27T07:37:09.457+0000] {task_command.py:426} INFO - Running <TaskInstance: REGISTRO_MEDIDORES.run_hop_pipeline scheduled__2025-05-01T15:00:00+00:00 [running]> on host ec14a5b8088e
[2025-06-27T07:37:09.637+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='REGISTRO_MEDIDORES' AIRFLOW_CTX_TASK_ID='run_hop_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-05-01T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-01T15:00:00+00:00'
[2025-06-27T07:37:09.639+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-27T07:37:09.828+0000] {docker.py:366} INFO - Starting docker container from image apache/hop:latest
[2025-06-27T07:37:09.856+0000] {docker.py:374} WARNING - Using remote engine or docker-in-docker and mounting temporary volume from host is not supported. Falling back to `mount_tmp_dir=False` mode. You can set `mount_tmp_dir` parameter to False to disable mounting and remove the warning
[2025-06-27T07:37:10.699+0000] {docker.py:436} INFO - 2025/06/27 07:37:10 - Running the entrypoint script with PID 6
[2025-06-27T07:37:10.710+0000] {docker.py:436} INFO - 2025/06/27 07:37:10 - The project folder for ProyectoSmartMed is set to: /files
[2025-06-27T07:37:10.717+0000] {docker.py:436} INFO - 2025/06/27 07:37:10 - The specified project folder exists
[2025-06-27T07:37:10.719+0000] {docker.py:436} INFO - 2025/06/27 07:37:10 - Registering project ProyectoSmartMed in the Hop container configuration
[2025-06-27T07:37:10.721+0000] {docker.py:436} INFO - 2025/06/27 07:37:10 - /opt/hop/hop-conf.sh --project=ProyectoSmartMed --project-create --project-home='/files' --project-config-file='project-config.json'
[2025-06-27T07:38:02.352+0000] {docker.py:436} INFO - Creating project 'ProyectoSmartMed'
[2025-06-27T07:38:02.878+0000] {docker.py:436} INFO - Project 'ProyectoSmartMed' was created for home folder : /files
[2025-06-27T07:38:03.150+0000] {docker.py:436} INFO - Configuration file for project 'ProyectoSmartMed' was saved to : file:/files/project-config.json
[2025-06-27T07:38:03.312+0000] {docker.py:436} INFO - 2025/06/27 07:38:03 - Not creating an environment in the container
[2025-06-27T07:38:03.316+0000] {docker.py:436} INFO - 2025/06/27 07:38:03 - Running a single hop workflow / pipeline (${PROJECT_HOME}/Pipelines/FINAL_REGISTRO_MEDIDORES.hpl)
[2025-06-27T07:38:30.554+0000] {docker.py:436} INFO - 2025/06/27 07:38:30 - HopRun - Enabling project 'ProyectoSmartMed'
[2025-06-27T07:38:31.091+0000] {docker.py:436} INFO - 2025/06/27 07:38:31 - HopRun - Starting pipeline: /files/Pipelines/FINAL_REGISTRO_MEDIDORES.hpl
[2025-06-27T07:38:31.109+0000] {docker.py:436} INFO - 2025/06/27 07:38:31 - FINAL_REGISTRO_MEDIDORES - Executing this pipeline using the Local Pipeline Engine with run configuration 'local'
[2025-06-27T07:38:31.259+0000] {docker.py:436} INFO - 2025/06/27 07:38:31 - FINAL_REGISTRO_MEDIDORES - Execution started for pipeline [FINAL_REGISTRO_MEDIDORES]
[2025-06-27T07:38:35.473+0000] {docker.py:436} INFO - 2025/06/27 07:38:35 - Table output.0 - Connected to database [POSTGRES_SMART] (commit=1000)
[2025-06-27T07:38:38.108+0000] {docker.py:436} INFO - 2025/06/27 07:38:38 - final_medidores.0 - Finished reading query, closing connection.
[2025-06-27T07:38:38.232+0000] {docker.py:436} INFO - 2025/06/27 07:38:38 - FINAL_REGISTRO_MEDIDORES - Pipeline duration : 7.12 seconds [  7.120" ]
[2025-06-27T07:38:38.296+0000] {docker.py:436} INFO - HopRun exit.
[2025-06-27T07:38:38.297+0000] {docker.py:436} INFO - 2025/06/27 07:38:38 - FINAL_REGISTRO_MEDIDORES - Execution finished on a local pipeline engine with run configuration 'local'
[2025-06-27T07:38:39.388+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-06-27T07:38:39.510+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=REGISTRO_MEDIDORES, task_id=run_hop_pipeline, run_id=scheduled__2025-05-01T15:00:00+00:00, execution_date=20250501T150000, start_date=20250627T073709, end_date=20250627T073839
[2025-06-27T07:38:39.613+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-06-27T07:38:39.695+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-06-27T07:38:39.699+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
